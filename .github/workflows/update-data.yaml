on:
  push:
    paths:
      - 'src/**.py'
      - 'data/**.csv'
    branches:
      - "main"
  workflow_dispatch:
name: update data and maps
jobs:
  github-action:
    runs-on: ubuntu-latest
    env:
      POSTGRES_HOST: ${{ secrets.POSTGRES_HOST }}
      POSTGRES_PORT: ${{ secrets.POSTGRES_PORT }}
      POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
      POSTGRES_PASS: ${{ secrets.POSTGRES_PASS }}
      POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
      POSTGRES_SCHEMA: ${{ secrets.POSTGRES_SCHEMA }}
      GWR_FILE: ${{ secrets.GWR_FILE }}
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      S3_ENDPOINT_URL: ${{ secrets.S3_ENDPOINT_URL }}
    steps:
      - uses: actions/checkout@master
      # Upload from repo and fetch data packages in workspace (newer wins)
      - name: setup python
        uses: actions/setup-python@v2
        with:
          python-version: 3.9
      - name: installing dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: update data and generate maps
        run: python src/run_pipeline.py
      # For committing newly generated snapshots
      - name: push
        uses: actions-x/commit@v2
